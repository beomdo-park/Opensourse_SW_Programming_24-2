{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 10\n",
    "open(\"cafe.txt\", \"w\", encoding=\"utf8\").write(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"cafe.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'UTF-8'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> 'utf-8'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "# 예제 11\n",
    "import sys, locale\n",
    "\n",
    "expressions = \"\"\"\n",
    "    locale.getpreferredencoding()\n",
    "    type(my_file)\n",
    "    my_file.encoding\n",
    "    sys.stdout.isatty()\n",
    "    sys.stdout.encoding\n",
    "    sys.stdin.isatty()\n",
    "    sys.stdin.encoding\n",
    "    sys.stderr.isatty()\n",
    "    sys.stderr.encoding\n",
    "    sys.getdefaultencoding()\n",
    "    sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open(\"dummy\", \"w\")\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), \"->\", repr(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 12\n",
    "from unicodedata import normalize\n",
    "\n",
    "s1 = \"café\"\n",
    "s2 = \"cafe\\u0301\"\n",
    "len(normalize(\"NFC\", s1)), len(normalize(\"NFC\", s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize(\"NFD\", s1)), len(normalize(\"NFD\", s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('café', 'café')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(\"NFC\", s1), normalize(\"NFC\", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('café', 'café')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(\"NFD\", s1), normalize(\"NFD\", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(\"NFC\", s1) == normalize(\"NFC\", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(\"NFD\", s1) == normalize(\"NFD\", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OHM SIGN'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 13\n",
    "from unicodedata import normalize, name\n",
    "\n",
    "ohm = \"\\u2126\"\n",
    "name(ohm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK CAPITAL LETTER OMEGA'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm_c = normalize(\"NFC\", ohm)\n",
    "name(ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ω', 'Ω', False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm, ohm_c, ohm == ohm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(\"NFC\", ohm) == normalize(\"NFC\", ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN SMALL LETTER SHARP S'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 14\n",
    "eszett = \"ß\"\n",
    "name(eszett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ß', 'ss', 'ß')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett_cf = eszett.casefold()  # casefold()는 모든 유니코드 문자를 소문자로 변환\n",
    "eszett_cf2 = eszett.lower()\n",
    "eszett, eszett_cf, eszett_cf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 15\n",
    "s1 = \"café\"\n",
    "s2 = \"cafe\\u0301\"  #'COMBINING ACUTE ACCENT' U+0301\n",
    "\n",
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize(\"NFC\", str1) == normalize(\"NFC\", str2)\n",
    "\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return normalize(\"NFC\", str1).casefold() == normalize(\"NFC\", str2).casefold()\n",
    "\n",
    "\n",
    "nfc_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(\"A\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = \"Straße\"\n",
    "s4 = \"strasse\"\n",
    "\n",
    "s3 == s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal('A','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 16\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"발음 구별 기호를 모두 제거한다.\"\"\"\n",
    "    norm_txt = unicodedata.normalize(\"NFD\", txt)\n",
    "    shaved = \"\".join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize(\"NFC\", shaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.\"'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = '\"Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.\"'\n",
    "shave_marks(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ζεφυρος, Zefiro'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Greek = 'Ζέφυρος, Zéfiro'\n",
    "shave_marks(Greek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Straße'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shave_marks('Straße')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafe'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shave_marks('café')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 17\n",
    "def shaved_marks_latin(txt):\n",
    "    \"\"\"라틴 기반 문자에서 발음 구별 기호를 모두 제거한다.\"\"\"\n",
    "    norm_txt = unicodedata.normalize(\"NFD\", txt)\n",
    "\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue  # 라틴 기반 문자에는 발음 구별 기호를 제거한다.\n",
    "        keepers.append(c)\n",
    "        # 발음 구별 기호가 아니면, 이 문자가 라틴 기반 문자인지 확인한다.\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = \"\".join(keepers)\n",
    "    return unicodedata.normalize(\"NFC\", shaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 18\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\", \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "multi_map = str.maketrans({\n",
    "    \"€\": \"<euro>\",\n",
    "    \"…\": \"...\",\n",
    "    \"Œ\": \"OE\",\n",
    "    \"™\": \"(TM)\",\n",
    "    \"œ\": \"oe\",\n",
    "    \"‰\": \"<per mille>\",\n",
    "    \"‡\": \"**\",\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"윈도우 코드 페이지 1252의 문자를 ASCII에 가깝게 변환한다.\"\"\"\n",
    "    return txt.translate(multi_map)\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks(txt)\n",
    "    no_marks = dewinize(no_marks)\n",
    "    return no_marks\n",
    "\n",
    "order = '\"Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.\"'\n",
    "dewinize(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Herr Voß: - ½ cup of OEtker(TM) caffe latte - bowl of acai.\"'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asciize(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acerola', 'atemoia', 'açaí', 'caju', 'cajá']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제 19\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyuca\n",
      "  Downloading pyuca-1.2-py2.py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 13.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pyuca\n",
      "Successfully installed pyuca-1.2\n"
     ]
    }
   ],
   "source": [
    "# 예제 20\n",
    "!pip install pyuca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyuca\n",
    "coll = pyuca.Collator()\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "sorted_fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "#예제 21\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r\"\\d\")\n",
    "sample = \"1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285\"\n",
    "\n",
    "for char in sample:\n",
    "    print(\n",
    "        \"U+%04x\" % ord(char),\n",
    "        char.center(6),\n",
    "        \"re_dig\" if re_digit.match(char) else \"-\",\n",
    "        \"isdig\" if char.isdigit() else \"-\",\n",
    "        \"isnum\" if char.isnumeric() else \"-\",\n",
    "        format(unicodedata.numeric(char), \"5.2f\"),\n",
    "        unicodedata.name(char),\n",
    "        sep=\"\\t\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " 'Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      " str : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      " bytes: [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      " str : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      " bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "#예제 22\n",
    "import re\n",
    "\n",
    "re_numbers_str = re.compile(r\"\\d+\")\n",
    "re_words_str = re.compile(r\"\\w+\")\n",
    "re_numbers_bytes = re.compile(rb\"\\d+\")\n",
    "re_words_bytes = re.compile(rb\"\\w+\")\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\" \" as 1729 = 1³ + 12³ = 9³ + 10³.\")\n",
    "text_bytes = text_str.encode(\"utf_8\")\n",
    "\n",
    "print(\"Text\", repr(text_str), sep=\"\\n \")\n",
    "print(\"Numbers\")\n",
    "print(\" str :\", re_numbers_str.findall(text_str))\n",
    "print(\" bytes:\", re_numbers_bytes.findall(text_bytes))\n",
    "print(\"Words\")\n",
    "print(\" str :\", re_words_str.findall(text_str))\n",
    "print(\" bytes:\", re_words_bytes.findall(text_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['55.ipynb', 'cafe.txt', 'dummy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 23\n",
    "import os\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'55.ipynb', b'cafe.txt', b'dummy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(b'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['digits-of-π.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제 24\n",
    "os.listdir('./fluent_python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'digits-of-\\xcf\\x80.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(b'./fluent_python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafe.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_name_bytes = os.listdir(b'.')[1]\n",
    "pi_name_str = pi_name_bytes.decode('ascii', 'surrogateescape')\n",
    "pi_name_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
